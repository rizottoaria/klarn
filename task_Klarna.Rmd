---
title: 'Klarna cases: application for Fraud Analyst – case Study'
author: "Oksana Laputskaya"
date: "6.08.2019"
output:
  html_document: default
  word_document: 
    fig_height: 4
    fig_width: 5
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
Read data from file to environment:
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
library(dplyr)
library(data.table)
fraudulent_transactoins<-read.csv("Klarna Overnight Case Study Data.csv",sep=';', encoding = "Latin-1",stringsAsFactors =F,flush=T)%>%filter(is.na(customer_id)==F)
fraudulent_transactoins$is_fraud<-factor(fraudulent_transactoins$is_fraud)

```

Let's have a look on data before making basic analysis:

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
str(fraudulent_transactoins)
summary(fraudulent_transactoins)
```


### 1.Basic Analysis

What is the proportion (%) of fraud to total transactions that meet the following criteria?
a.	Purchase in the Clothing Segment
b.	Purchases Greater than 1000 SEK
c.	Purchases coming from UK 
**1. a**
```{r}
fraudulent_transactoins%>%filter(type_of_goods==' Clothing ')%>%select(is_fraud)%>%table%>%prop.table()

```
proportion is *3.27752%*

**1. b**


```{r}
fraudulent_transactoins%>%filter(as.numeric(sub(',','',purchase_amount))>1000)%>%select(is_fraud)%>%table%>%prop.table
```
proportion is *8,43299%*

**1. c**

```{r}
fraudulent_transactoins%>%filter(ip_country==' UK ')%>%select(is_fraud)%>%table%>%prop.table
```
proportion is **40,83333%**


###2.	Trend Analysis

**2. a.	Which three data subcategories in the 12 variables (e.g. type_of_goods_ = books or ip_country=SE) have the highest value (SEK) of fraudulent transactions**

Before finding three data subcategories let's transform our data for more comfortable analysis.

```{r message=FALSE, warning=FALSE, paged.print=TRUE}
#save time of purchases as a float number
library(lubridate)
fraudulent_transactoins$time_of_purchase<-round(as.numeric(hms(fraudulent_transactoins$time_of_purchase)) / 3600,digits=1)
for(i in  names(fraudulent_transactoins[-c(3)])){fraudulent_transactoins[,i]<-as.factor(fraudulent_transactoins[,i])}
fraudulent_transactoins_for_max<-fraudulent_transactoins%>%filter(is_fraud==' t ')%>%select(-c('п.їtransaction_id','customer_id','is_fraud' ))%>%as.data.frame(stringsAsFactors=T)
fraudulent_transactoins_for_max$purchase_amount<-as.numeric(sub(',','',gsub(' ','', fraudulent_transactoins_for_max$purchase_amount)))
```

Let's find a sum of crime purchase_amount with different factors

```{r message=FALSE, warning=FALSE}
values<-as.character()
for(i in  names(fraudulent_transactoins_for_max)[-c(2)]){values<-rbind(values,cbind(i,fraudulent_transactoins_for_max%>%group_by(fraudulent_transactoins_for_max[,i])%>%summarize(value=sum(purchase_amount))))}
values%>%arrange(desc(value))%>%head(n=3L)
```
So the most fraudulent sub-categories are has_paid_before=‘f’, ip_country=NA and type_of_goods=Tickets

**2.b. Briefly explain why these subcategories would be indicative of fraud.**

The explanation of the fact that these subcategories of fraud-hazardous is trivially enough - new customers are like a wild card, we don’t have any knowledge about their behavior, so they can make only one fraudulent transaction and vanish. Also, ip_country can mean that customer use VPN and don't want to be defined. And the purchase of tickets is quite fraudulent because you can get the purchase on your e-mail, crooks use stolen credit cards to purchase airline tickets and then cancel them, in order to get a flight credit and a confirmation number. A series of airlines worldwide make it pretty easy to pull this.

### 3.Fraud rule creation

**3.a. What is the hit and catch rate for the 3 data subcategories from assignment 2.**

I numerate subcategories from previous part - 1,2,3.

Find hit and catch rate for these subcategories:

```{r}
hit_rate_1<-as.character((fraudulent_transactoins%>%filter(has_paid_before==' f '&is_fraud==' t ')%>%select(is_fraud)%>%count())/(fraudulent_transactoins%>%filter(has_paid_before==' f ')%>%select(is_fraud)%>%count()))
catch_rate_1<-as.character((fraudulent_transactoins%>%filter(has_paid_before==' f '&is_fraud==' t ')%>%select(is_fraud)%>%count())/(fraudulent_transactoins%>%filter(is_fraud==' t ')%>%select(is_fraud)%>%count()))

hit_rate_2<-as.character((fraudulent_transactoins%>%filter(ip_country==''&is_fraud==' t ')%>%select(is_fraud)%>%count())/(fraudulent_transactoins%>%filter(ip_country=='')%>%select(is_fraud)%>%count()))
catch_rate_2<-as.character((fraudulent_transactoins%>%filter(ip_country==''&is_fraud==' t ')%>%select(is_fraud)%>%count())/(fraudulent_transactoins%>%filter(is_fraud==' t ')%>%select(is_fraud)%>%count()))

hit_rate_3<-as.character((fraudulent_transactoins%>%filter(type_of_goods==' Tickets '&is_fraud==' t ')%>%select(is_fraud)%>%count())/(fraudulent_transactoins%>%filter(type_of_goods==' Tickets ')%>%select(is_fraud)%>%count()))
catch_rate_3<-as.character((fraudulent_transactoins%>%filter(type_of_goods==' Tickets '&is_fraud==' t ')%>%select(is_fraud)%>%count())/(fraudulent_transactoins%>%filter(is_fraud==' t ')%>%select(is_fraud)%>%count()))  
parameters<-data.frame(c(hit_rate_1,catch_rate_1),c(hit_rate_2,catch_rate_2),c(hit_rate_3,catch_rate_3),row.names=c("hitrate","catchrate"))
names(parameters)<-paste("Rule",1:3)
parameters
```
We can notice, that cacht rate on first rule is rather big, but hitrate is not so big, it means, that 
**3.b Try to combine variables and use cut-offs / sub-categories to improve hit rate and catch rate (provide at least 2 examples of fraud rules).**

We can build fraud rules in different ways, e.g. make a conditional inference tree of binary classification, regression model or some random forest.

Let’s make a conditional inference tree with our variables to improve the hit rate and catch rate, fraud is rather rare, so we can split the train set/test set as 60%/40%.

```{r}
fraudulent_transactoins$purchase_amount<-as.numeric(sub(',','',gsub(' ','', fraudulent_transactoins$purchase_amount)))
library(rpart)
library(rpart.plot)
set.seed(2)
rn = sample(1:nrow(fraudulent_transactoins), 0.6*nrow(fraudulent_transactoins))
dt_train = fraudulent_transactoins[rn,]
dt_test = fraudulent_transactoins[-rn,]

# build model
multi.class.model <- rpart(as.factor(is_fraud)~ as.factor(ip_country) + as.factor(type_of_goods) + as.factor(has_paid_before), data = dt_train)
# visualise model
rpart.plot(multi.class.model)
```

Let's use model on the other set and count catch_rate and hit_rate for prediction:

```{r}
table(predict(multi.class.model, newdata=dt_test,type='class'),dt_test$is_fraud)
table(dt_test$is_fraud)
#hit_rate
hit_rate<-(table(predict(multi.class.model, newdata=dt_test,type='class'),dt_test$is_fraud)[4])/(table(predict(multi.class.model, newdata=dt_test,type='class'),dt_test$is_fraud)[2]+table(predict(multi.class.model, newdata=dt_test,type='class'),dt_test$is_fraud)[3]+table(predict(multi.class.model, newdata=dt_test,type='class'),dt_test$is_fraud)[4])
#catch_rate 
catch_rate <-(table(predict(multi.class.model, newdata=dt_test,type='class'),dt_test$is_fraud)[4])/table(dt_test$is_fraud)[2]
parameters_new<-data.frame(c(hit_rate,catch_rate),row.names=c("hitrate","catchrate"))
names(parameters_new)<-paste("Rule",4)
parameters_new
```
As we see our new rule can predict fraud not ideally, but hitrate and catchrate more like each other,then in previous rules.
Let's make another rule and use Logistic regression. It is often used in credit scoring models, so we can use in in our binary classification.

```{r}
model<-glm(as.factor(is_fraud)~ as.factor(ip_country) + as.factor(type_of_goods) + as.factor(has_paid_before), data = dt_train,family=binomial())
predictResult <- predict(model, newdata = dt_test, type="response")
dt_test$is_fraud_pred[predictResult >= 0.5] = 1
dt_test$is_fraud_pred[predictResult < 0.5] = 0
table(dt_test$is_fraud_pred,dt_test$is_fraud)
table(dt_test$is_fraud)
hit_rate<-(table(dt_test$is_fraud_pred,dt_test$is_fraud)[4])/(table(dt_test$is_fraud_pred,dt_test$is_fraud)[2]+table(dt_test$is_fraud_pred,dt_test$is_fraud)[3]+table(dt_test$is_fraud_pred,dt_test$is_fraud)[4])
#catch_rate 
catch_rate <-(table(dt_test$is_fraud_pred,dt_test$is_fraud)[4])/table(dt_test$is_fraud)[2]
parameters_new2<-data.frame(c(hit_rate,catch_rate),row.names=c("hitrate","catchrate"))
names(parameters_new2)<-paste("Rule",5)
parameters_new2
```

**3. c.	Explain why both hit rate and catch rate are relevant parameters? What others factors might be important when creating and assessing new fraud rules?**

Hit rate and catch rate are both important because it is both important not to lose honest customers(by incorrect fraud detection) and not to lose money(without fraud detection). New rules shouldn’t work excessively, but they should not be snapped up too rarely, skipping fraud cases. The model must be balanced.


### 4.Some information is very indicative of fraud but hard to extract from the raw variables.

**4.a.	Look into how variables (customer_id included) can be combined or processed to form new variables that are predictive of fraud?**

We can make a model, which use all factors to predict fraud. Some of them could be replaced with frequence(for example, customer_id and email, because these variables have too many levels of factors). Then categorial variables can be transform to binary(1 or 0) for every subcategory (`r dim(values)[1]` subcategories in total) and then it can be suitable to use such algorithms as Generalized Boosted Regression Modeling (GBM) or KNN.

```{r message=FALSE, warning=FALSE, paged.print=TRUE}

fraudulent_transactoins<-fraudulent_transactoins%>%group_by(customer_id)%>%summarize(n())%>%left_join(fraudulent_transactoins)%>%select(-customer_id)%>%mutate(customer_id=`n()`)
fraudulent_transactoins<-fraudulent_transactoins%>%group_by(email)%>%summarize(n())%>%left_join(fraudulent_transactoins)%>%select(-email)%>%mutate(email=`n()`)%>%select(-`n()`)

```
**4.b Describe a process/method for processing and combining variables in general and how it relates to different types of fraud (stolen identity, providing fake information etc.)**

When we have a huge dataset, it’s not too easy to find the right criteria. For example, we can make a decision tree and then clip some useless branches to use only significant variables in the model. The difficultness of fraud detection connects with a time lag. We often detect fraud post-factum and use these cases to teach models (as it was in Task 2). For example, to make a prediction easier we can identify stolen cards that were used between the time of the reported instance and the time that the card was canceled. Recognizing the unique challenges in developing fraud models, the ability to be pre-emptive vs. reactive in addressing fraud can yield tremendous benefits. Using pre-emptive with predictive models allows taking advantage of these benefits.  
